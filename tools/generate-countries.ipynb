{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note book to create html pages for countries and Kreise in Germany"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New strategy (with pelican)\n",
    "\n",
    "- put notebooks into wwwroot/ipynb folder\n",
    "- put html into html wwwroot/folder\n",
    "- pelican files can then go into wwwroot folder\n",
    "\n",
    "Advantages:\n",
    "- cleaner than all in one folder\n",
    "- github can display all files in each subdirectory (there is a limit of 500 files or so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from nbconvert import HTMLExporter\n",
    "from nbconvert.writers import FilesWriter\n",
    "\n",
    "import nbformat\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#  Set to false if you do not want multiprocessing enabled\n",
    "cores = 'auto'\n",
    "if cores == 'auto':\n",
    "    cores = max(1, cpu_count()-2)\n",
    "\n",
    "if cores:\n",
    "    print(f'Using {cores} processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%cp -v ../coronavirus.py .\n",
    "from coronavirus import *\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)  #  Disable pandas scientific notation\n",
    "# force download of new data\n",
    "clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also delete date in place where notebooks are executed\n",
    "!rm -rf wwwroot/ipynb/cachedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, c = fetch_deaths(), fetch_cases()\n",
    "\n",
    "countries = d.index\n",
    "countries2 = c.index\n",
    "assert (countries2 == countries).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_template(templatefile, output_file_name, mappings, wwwroot):\n",
    "    \"\"\"Create concrete *.ipynb file from template\n",
    "    - templatefile: the template with placeholders to be substituted\n",
    "    - mappings: dictiorany with placeholders as keys, and values to be substituted\n",
    "    - output_file_name: name to write modified file to\n",
    "    - wwwroot: directory in which the output file should be written\n",
    "    \"\"\"\n",
    "    # open template\n",
    "    with open(templatefile, \"tr\") as f_template:\n",
    "        template = f_template.read()\n",
    "    for key in mappings:\n",
    "        template = template.replace(key, mappings[key])\n",
    "    with open(os.path.join(wwwroot, output_file_name), \"tw\") as f:\n",
    "        f.write(template)\n",
    "    print(f\"Written file to {output_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_country_name_is_known(name):\n",
    "    d = fetch_deaths()\n",
    "    assert name in d.index, f\"{name} is unknown. Known countries are {sorted(d.index)}\"\n",
    "\n",
    "def germany_check_region_name_is_known(name):\n",
    "    d = fetch_data_germany()\n",
    "    assert name in list(d['Bundesland'].drop_duplicates()), \\\n",
    "        f\"{name} is unknown. Known regions are {sorted(list(d['Bundesland'].drop_duplicates()))}\"\n",
    "\n",
    "def germany_check_subregion_name_is_known(name):\n",
    "    d = fetch_data_germany()\n",
    "    assert name in list(d['Landkreis'].drop_duplicates()), \\\n",
    "        f\"{name} is unknown. Known regions are {sorted(list(d['Landkreis'].drop_duplicates()))}\"\n",
    "\n",
    "germany_check_region_name_is_known(\"Hamburg\") \n",
    "germany_check_subregion_name_is_known(\"SK Hamburg\") \n",
    "\n",
    "    \n",
    "def sanitise(name):\n",
    "    \"\"\"Given a country name as a string, sanitise it for use as URL and filename: \n",
    "    - get rid of spaces, commas\n",
    "    \n",
    "    return cleaned string.\n",
    "    \n",
    "    (Leave umlaute for now)\n",
    "    \"\"\"\n",
    "    s = name.replace(\" \", \"-\")\n",
    "    s = s.replace(\",\", \"-\")\n",
    "    return s\n",
    "    \n",
    "    \n",
    "def get_binder_url(notebook):\n",
    "    \"\"\"Given a notebook name, compute the path\"\"\"\n",
    "    base = \"https://mybinder.org/v2/gh/fangohr/coronavirus/master?filepath=ipynb/\"\n",
    "    return base + notebook.replace(\" \", \"%20\")\n",
    "\n",
    "\n",
    "def create_ipynb_for_country(country, templatename, wwwroot):\n",
    "    \"\"\"Creates ipynb file for country, based on templatename. \n",
    "    File is based in ipynb subfolder of wwwroot.\n",
    "    Returns name of file.\"\"\"\n",
    "    \n",
    "    # create ipynb folder if required\n",
    "    ipynb_dir = os.path.join(wwwroot, \"ipynb\")\n",
    "    if not os.path.exists(ipynb_dir):\n",
    "        os.mkdir(ipynb_dir)\n",
    "        \n",
    "    \n",
    "    check_country_name_is_known(country)\n",
    "    \n",
    "    output_file_name =  f\"{country}.ipynb\"\n",
    "    output_file_path = os.path.join(wwwroot, \"ipynb\", output_file_name)\n",
    "    \n",
    "    # country = sanitize(country)\n",
    "    mappings = {\n",
    "        \"%title%\" : country,\n",
    "        \"%title2%\" : \"\",\n",
    "        \"%country%\" : country,\n",
    "        \"%binderurl%\" : get_binder_url(output_file_name),\n",
    "        \"%create_date%\" : datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "    modify_template(templatename, os.path.join(\"ipynb\", output_file_name), mappings, wwwroot)\n",
    "    assert os.path.exists(output_file_path), f\"{output_file_path} does not exist\"\n",
    "    return output_file_name\n",
    "\n",
    "def create_ipynb_for_germany(region, subregion, templatename, wwwroot):\n",
    "    \"\"\"Creates ipynb file for region and subregion in Germany, based on templatename. \n",
    "    File is based in ipynb subfolder of wwwroot.\n",
    "    Returns name of file.\"\"\"\n",
    "    germany_check_region_name_is_known(region)\n",
    "    germany_check_subregion_name_is_known(subregion)\n",
    "    \n",
    "    output_file_name =  f\"Germany-{sanitise(region)}-{sanitise(subregion)}.ipynb\"\n",
    "    output_file_path = os.path.join(wwwroot, \"ipynb\", output_file_name)\n",
    "    \n",
    "    # country = sanitize(country)\n",
    "    mappings = {\n",
    "        \"%title%\" : f\"Germany: {subregion} ({region})\",\n",
    "        \"%title2%\" : \"\",\n",
    "        \"%region%\" : region,\n",
    "        \"%subregion%\" : subregion,\n",
    "        \"%binderurl%\" : get_binder_url(output_file_name),\n",
    "        \"%create_date%\" : datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    }\n",
    "\n",
    "    modify_template(templatename, os.path.join(\"ipynb\", output_file_name), mappings, wwwroot)\n",
    "    assert os.path.exists(output_file_path), f\"{output_file_path} does not exist\"\n",
    "    return output_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_executor = ExecutePreprocessor()\n",
    "nb_executor.allow_errors = True\n",
    "\n",
    "html_exporter = HTMLExporter()\n",
    "html_writer = FilesWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_convert_html(nb_path, outdir):\n",
    "    filename = os.path.basename(nb_path)\n",
    "    outpath = os.path.join(outdir, os.path.splitext(filename)[0])\n",
    "    with open(nb_path) as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "        nb = nb_executor.preprocess(nb)[0]\n",
    "        body, resources = html_exporter.from_notebook_node(nb)\n",
    "        html_writer.write(body, resources, outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbconvert_ipynb2html(ipynb_name, wwwroot):\n",
    "    \"\"\"Given the name of a a notebook (such as \"germany.ipynb\"), create the \n",
    "    corresponding html file (\"html/germany.html\") from the notebook file in \n",
    "    \"ipynb\" and return the name of the file (i.e. germany.html).\n",
    "    \"\"\"\n",
    "    ipynb_dir = os.path.join(wwwroot, \"ipynb\")\n",
    "    \n",
    "    # copy file to run the notebook\n",
    "    shutil.copyfile(\"../coronavirus.py\", os.path.join(ipynb_dir, \"../coronavirus.py\"))\n",
    "    \n",
    "    # copy requirements (needed for binder)\n",
    "    shutil.copyfile(\"../requirements.txt\", os.path.join(ipynb_dir, \"../requirements.txt\"))\n",
    "    \n",
    "    # execute notebook and create html copy from it\n",
    "    nb_convert_html(\n",
    "        os.path.join(ipynb_dir, ipynb_name),\n",
    "        os.path.join(wwwroot, \"html\")\n",
    "    )\n",
    "\n",
    "    # compute output path\n",
    "    output_file_name = os.path.splitext(ipynb_name)[0] + \".html\"\n",
    "    assert os.path.exists(os.path.join(wwwroot, \"html\", output_file_name))\n",
    "    \n",
    "    return output_file_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_md_index_list(title, links):\n",
    "    lines = []\n",
    "    lines.append(title)\n",
    "    lines.append(\"\")   # need empty line for markdown syntax\n",
    "\n",
    "    death_table = d.drop(columns=[\"Province/State\", \"Lat\", \"Long\"]).sum(axis=1, skipna=True).to_frame(name=\"Total deaths\")\n",
    "    cases_table = c.drop(columns=[\"Province/State\", \"Lat\", \"Long\"]).sum(axis=1, skipna=True).to_frame(name=\"Total cases\")\n",
    "    index_table = cases_table.join(death_table)\n",
    "    index_table = index_table.groupby(\"Country/Region\").sum()\n",
    "    \n",
    "    rename_dict = {}\n",
    "    for name, (name_html, name_ipynb) in links.items():\n",
    "        path_html = os.path.join('html', name_html)\n",
    "        rename_dict[name] = f\"[{name}]({path_html})\"\n",
    "\n",
    "    index_table = index_table.rename(index=rename_dict)\n",
    "    index_table[\"Total deaths\"] = index_table[\"Total deaths\"].apply(lambda x: '{:d}'.format(x)) #  Disable pandas scientific notation\n",
    "    index_table[\"Total cases\"] = index_table[\"Total cases\"].apply(lambda x: '{:d}'.format(x)) #  Disable pandas scientific notation\n",
    "\n",
    "    return index_table.to_markdown()\n",
    "\n",
    "def test_create_md_index_list():\n",
    "    title = \"Title\"\n",
    "    links = {\"Afghanistan\" : (\"Afghanistan.html\", \"Afghanistan.ipynb\")}\n",
    "    assert create_md_index_list(title, links).split(\"\\n\")[2].split(\"|\")[1] == ' [Afghanistan](html/Afghanistan.html) '\n",
    "    \n",
    "test_create_md_index_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_list():\n",
    "    d, c = fetch_deaths(), fetch_cases()\n",
    "\n",
    "    countries = d.index\n",
    "    countries2 = c.index\n",
    "    assert (countries2 == countries).all()\n",
    "    \n",
    "    # Here we should identify regions in countries, and process those.\n",
    "    # Instead, as a quick hack to get started, we'll just take one country\n",
    "    # and the current \"get_country\" method will sum over all regions of one country if only \n",
    "    # the country name is given.\n",
    "    \n",
    "    return sorted(countries.drop_duplicates())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_page(sections, rootname, wwwroot):\n",
    "    \"\"\"Sections is dictionary: key is title, value is markdown text\"\"\"\n",
    "    md_file = rootname + \".md\"\n",
    "    \n",
    "    with open(os.path.join(wwwroot, md_file), \"tw\") as f:\n",
    "        for section in sections:\n",
    "            f.write(f\"# {section}\\n\\n\")\n",
    "            f.write(sections[section])\n",
    "    print(f\"Written overview to {md_file}.\")\n",
    "    html_file = rootname + \".html\"\n",
    "    subprocess.check_call(f\"pandoc -t html -o {os.path.join(wwwroot, html_file)} \" +\n",
    "                          f\"{os.path.join(wwwroot, md_file)}\", shell=True)\n",
    "    return html_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_germany_subregion_list():\n",
    "    \"\"\"returns list of subregions (Kreise), \n",
    "    ordered according to (i) Land, then (ii) Kreis\n",
    "    \"\"\"\n",
    "    x = fetch_data_germany()\n",
    "    land_kreis = x[['Bundesland', 'Landkreis']]\n",
    "    ordered = land_kreis.sort_values(['Bundesland', 'Landkreis'])\n",
    "    return list(ordered['Landkreis'].drop_duplicates())\n",
    " \n",
    "\n",
    "@joblib_memory.cache\n",
    "def germany_get_bundesland_from_kreis(kreis):\n",
    "        x = fetch_data_germany()\n",
    "        return x[x['Landkreis'] == kreis].iloc[0]['Bundesland']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_wwwroot_exist(wwwroot):\n",
    "    if not os.path.exists(wwwroot):\n",
    "        msg = \"To put the html into github repo for webhosting, run \"\n",
    "        msg += '\"git clone git@github.com:fangohr/coronavirus.git wwwroot\" or similar'\n",
    "        # os.mkdir(wwwroot)\n",
    "        raise ValueError(f\"directory {wwwroot} missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_for_john_hopkins_countries(countries, wwwroot):\n",
    "    \"\"\"countries: list of strings with countrie names\n",
    "    \n",
    "    returns dictionary: keys are countrynames, values are tuples with path to html file and path to notebook\"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    does_wwwroot_exist(wwwroot)\n",
    "    created_files = {}\n",
    "\n",
    "    for i, country in enumerate(countries):\n",
    "        try:\n",
    "            print(f\"Processing {i+1}/{len(countries)} [{time.time()-start_time:4.0f}s]\")\n",
    "            ipynb_name = create_ipynb_for_country(country, \"template-country.ipynb\", wwwroot=wwwroot)\n",
    "            html_name = nbconvert_ipynb2html(ipynb_name, wwwroot=wwwroot)\n",
    "            created_files[country] = html_name, ipynb_name\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {country}\", end='')\n",
    "            print(e)\n",
    "\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    print(f\"Create {len(countries)} notebooks and html versions in \" + \\\n",
    "          f\"{time.time()-start_time} seconds\")\n",
    "    \n",
    "    sys.stdout.flush()\n",
    "    return created_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_html_for_countries(countries, wwwroot, pool):\n",
    "    processes = pool._processes\n",
    "    padding = processes - (len(countries) % processes)\n",
    "    countries = countries + ([0] * padding)\n",
    "    per_process = int(len(countries)/processes)\n",
    "    countries_per_process = list(countries[i:i+per_process] for i in range(0, len(countries), per_process))\n",
    "    countries_per_process[-1] = countries_per_process[-1][:-padding]\n",
    "    \n",
    "    tasks = ((c, wwwroot) for c in countries_per_process)\n",
    "    \n",
    "    res = pool.starmap(create_html_for_john_hopkins_countries, tasks)\n",
    "    sys.stdout.flush()\n",
    "    combined_res = {}\n",
    "    \n",
    "    [combined_res.update(r) for r in res]\n",
    "    \n",
    "    return combined_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_markdown_index_page(md_content, title, pelican_file_path, \n",
    "                               save_as, wwwroot):\n",
    "    \"\"\"Create pelican markdown file, like this:\n",
    "    \n",
    "    title: Germany\n",
    "    category: Data\n",
    "    tags: data, plots\n",
    "    save-as: germany\n",
    "    date: 2020-04-11 08:00\n",
    "    \"\"\"\n",
    "\n",
    "    with open(os.path.join(pelican_file_path), \"tw\") as f:\n",
    "        f.write(f\"title: {title}\\n\")\n",
    "        f.write(f\"category: Data\\n\")\n",
    "        f.write(f\"tags: data, plots\\n\")\n",
    "        f.write(f\"save-as: {save_as}\\n\")\n",
    "        date_time = datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M\")\n",
    "        f.write(f\"date: {date_time}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(md_content)\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create country overview for the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwwroot = \"wwwroot\"\n",
    "countries = get_country_list()\n",
    "if cores:\n",
    "    with Pool(cores) as pool:\n",
    "        created_files = parallel_html_for_countries(countries, wwwroot, pool)\n",
    "else:\n",
    "    created_files = create_html_for_john_hopkins_countries(countries, wwwroot)\n",
    "\n",
    "index_md = create_md_index_list(\"Countries\", created_files)\n",
    "create_markdown_index_page(index_md, title=\"World\", \n",
    "                           pelican_file_path=\"pelican/content/world.md\", save_as=\"world\", \n",
    "                           wwwroot=wwwroot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create list of Germany data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_html_for_Germany(subregions, wwwroot):\n",
    "    does_wwwroot_exist(wwwroot)\n",
    "    start_time = time.time()\n",
    "    created_files = {}\n",
    "\n",
    "    for i, kreis in enumerate(subregions):\n",
    "        try:\n",
    "            bundesland = germany_get_bundesland_from_kreis(kreis)\n",
    "            print(f\"Processing {i+1}/{len(subregions)} [{time.time()-start_time:4.0f}s]\")\n",
    "            ipynb_name = create_ipynb_for_germany(region=bundesland, subregion=kreis, \n",
    "                                                  templatename=\"template-germany.ipynb\", wwwroot=wwwroot)\n",
    "            html_name = nbconvert_ipynb2html(ipynb_name, wwwroot=wwwroot)\n",
    "            one_line_summary = f\"Germany: {bundesland} : {kreis}\"\n",
    "            created_files[one_line_summary] = html_name, ipynb_name\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {kreis}\", end='')\n",
    "            print(e)\n",
    "\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print(f\"Create {len(subregions)} notebooks and html versions in\" + \\\n",
    "          f\"{time.time()-start_time} seconds\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return created_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_html_for_germany(subregions, wwwroot, pool):\n",
    "    processes = pool._processes\n",
    "    padding = processes - (len(subregions) % processes)\n",
    "    subregions = subregions + ([0] * padding)\n",
    "    per_process = int(len(subregions)/processes)\n",
    "    subregions_per_process = list(subregions[i:i+per_process] for i in range(0, len(subregions), per_process))\n",
    "    subregions_per_process[-1] = subregions_per_process[-1][:-padding]\n",
    "    \n",
    "    tasks = ((c, wwwroot) for c in subregions_per_process)\n",
    "    \n",
    "    res = pool.starmap(create_html_for_Germany, tasks)\n",
    "    sys.stdout.flush()\n",
    "    combined_res = {}\n",
    "    \n",
    "    [combined_res.update(r) for r in res]\n",
    "    \n",
    "    return combined_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwwroot = \"wwwroot\"\n",
    "subregions = get_germany_subregion_list()\n",
    "\n",
    "# data cleaning: on 13 April, we had a Landkreis \"LK Göttingen (alt)\"\n",
    "# with only one data point. This causes plots to fail, because there\n",
    "# is nothing to plot, and then the legend() command failed.\n",
    "# We assume that the RKI labels unusual data with '(alt)', and remove those.\n",
    "\n",
    "alt_data_sets = [x for x in subregions if \"(alt)\" in x.lower()]\n",
    "if len(alt_data_sets) > 0:\n",
    "    print(f\"Removing datasets label with '(alt)': {alt_data_sets}\")\n",
    "    for alt in alt_data_sets:\n",
    "        c, d = germany_get_region(landkreis=alt)\n",
    "        print(f\"  removed: {alt} : len(cases)={len(c)}, len(deaths)={len(d)}\")\n",
    "    subregions = [x for x in subregions if not \"(alt)\" in x.lower()]\n",
    "\n",
    "if cores:\n",
    "    with Pool(cores) as pool:\n",
    "        created_files = parallel_html_for_germany(subregions, wwwroot, pool)\n",
    "else:\n",
    "    created_files = create_html_for_Germany(subregions, wwwroot)\n",
    "\n",
    "index_md = create_md_index_list(\"Landkreise in Germany\", \n",
    "                                created_files)\n",
    "\n",
    "create_markdown_index_page(index_md, title=\"Germany\", \n",
    "                           pelican_file_path=\"pelican/content/germany.md\", save_as=\"germany\", \n",
    "                           wwwroot=wwwroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c, d = germany_get_region(landkreis='LK Göttingen (alt)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2, d2 = germany_get_region(landkreis='LK Göttingen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
