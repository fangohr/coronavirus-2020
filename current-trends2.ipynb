{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare exponential and polynomial fit. Needs tidy up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use data from the files at https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "Thank you @CSSEGISandData for providing the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iminuit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e00daa82c459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0miminuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'iminuit'"
     ]
    }
   ],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import math\n",
    "from numpy import log, exp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "figsize = (8, 6)   # need bigger size otherwise xlabels are cut-off in svg files\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "sb.set_style('darkgrid')\n",
    "import scipy\n",
    "import numpy as np\n",
    "import iminuit\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "\n",
    "def string_to_date(input_):\n",
    "    \"\"\"Converts string of type 01/22/02 [for 22 Jan 2020] into datetime object\"\"\"\n",
    "    # return pd.to_datetime(input_, format='%m/%d/%y', errors='ignore')\n",
    "    return pd.to_datetime(input_, format='%m/%d/%y')\n",
    "\n",
    "def set_date_formatting(ax):\n",
    "    ax.xaxis.set_major_locator(matplotlib.dates.DayLocator())\n",
    "    ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b %d'))\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "# read data from web\n",
    "#\n",
    "\n",
    "def fetch_data(names = ['confirmed', 'deaths']):\n",
    "    \"\"\"Return 3 data frames:\n",
    "    [confirmed, deaths], location_info\n",
    "    \n",
    "    where confirmed, deaths and recovered are data frames with countries/regions in the rows, and \n",
    "    days in the columns\n",
    "    \n",
    "    and location_info provides additional information about the locations.\n",
    "    \n",
    "    We assume all three tables have the same entries\"\"\"\n",
    "    location_info = pd.DataFrame()\n",
    "    dfs = []\n",
    "    for name in names:\n",
    "        url = os.path.join(base_url, \"time_series_covid19_\" + name + \"_global.csv\")\n",
    "        df = pd.read_csv(url, index_col=1)\n",
    "    \n",
    "        if not name == 'Recovered':\n",
    "            location_info['Lat'] = df['Lat']\n",
    "            location_info['Long'] = df['Long']\n",
    "            location_info['Province/State'] = df['Province/State']\n",
    "            location_info['location'] = df.index + \"-\" + df['Province/State']\n",
    "        else:\n",
    "            pass  # no location info in recovered since 14 March\n",
    "        ## df = df.drop(labels=[\"Lat\", \"Long\", \"Province/State\"], axis=1)\n",
    "        df = df.drop(labels=[\"Lat\", \"Long\"], axis=1)\n",
    "        \n",
    "        # extract dates from strings\n",
    "        dates = string_to_date(df.columns[1:])        \n",
    "        # use those objects as new column labels\n",
    "        df.columns = [df.columns[0]] + list(dates)\n",
    "        print(f\"{name:10}: last data point from {max(dates[1:])}\")\n",
    "        # dfs.append([df, location_info)\n",
    "        dfs.append(df)\n",
    "\n",
    "    return dfs\n",
    "\n",
    "\n",
    "confirmed, deaths = fetch_data()\n",
    "\n",
    "# show counries with mosth deaths\n",
    "deaths.sort_values(by=deaths.columns[-1], ascending=False).iloc[0:10,-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths.sort_values(by=deaths.columns[-1], ascending=False).iloc[:,-8:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_time_exponential(t1, t2, q1, q2):\n",
    "    return (t2 - t1) * (log(2) / log(q2/q1) )\n",
    "\n",
    "def growth_rate(double_time):\n",
    "    return log(2)/double_time\n",
    "\n",
    "\n",
    "# t1, t2, q1, q2 = 0, 1, 1, 2\n",
    "# double_time_exponential(t1, t2, q1, q2), growth_rate(double_time_exponential(t1, t2, q1, q2) )\n",
    "\n",
    "def double_time_exponential(q2_div_q1, t2_minus_t1=None):\n",
    "    # print(f\"double_time_exponential: {q2_div_q1}, {t2_minus_t1} \")\n",
    "    if t2_minus_t1 is None:\n",
    "        t2_minus_t1 = np.ones(q2_div_q1.shape)\n",
    "        # print(f\"shape t: {t2_minus_t1.shape}, shape q: {q2_div_q1.shape}\")\n",
    "        # print(f\"type t: {type(t2_minus_t1)}, type q: {type(q2_div_q1.shape)}\")\n",
    "\n",
    "    return t2_minus_t1 * np.log(2) / np.log(q2_div_q1) \n",
    "\n",
    "\n",
    "def stack_country(country = \"Germany\"):\n",
    "\n",
    "    #create one DataFrame for country/region\n",
    "    c_df = pd.DataFrame()\n",
    "    if country == \"United Kingdom\":\n",
    "        # UK has three Provinces: Channel Islands, Gibraltar and UK. Only need last one\n",
    "        c_df['confirmed'] = confirmed.loc[country].iloc[-1].drop('Province/State')\n",
    "        c_df['deaths'] = deaths.loc[country].iloc[-1].drop('Province/State')\n",
    "    elif country == \"China\": \n",
    "        # Use only Hubei province\n",
    "        tmp = confirmed.loc[country]\n",
    "        c_df['confirmed'] = tmp[tmp['Province/State'] == \"Hubei\"].T['China']\n",
    "        tmp = deaths.loc[country]\n",
    "        c_df['deaths'] = tmp[tmp['Province/State'] == \"Hubei\"].T['China']\n",
    "        c_df.drop(\"Province/State\", inplace=True)\n",
    "    elif country in ['US', 'France']:\n",
    "        c_df['confirmed'] = confirmed.loc[country].sum()\n",
    "        c_df['deaths'] = deaths.loc[country].sum()\n",
    "        c_df.drop('Province/State', inplace=True)\n",
    "    else:\n",
    "        c_df['confirmed'] = confirmed.loc[country].drop('Province/State')\n",
    "        c_df['deaths'] = deaths.loc[country].drop('Province/State')\n",
    "\n",
    "    # drop days with confirmed cases = 0\n",
    "    c1 = c_df[c_df['confirmed'] != 0][1:]\n",
    "    \n",
    "    # drop another row\n",
    "    c_df = c1\n",
    "  \n",
    "    c_df.index = string_to_date(c_df.index)\n",
    "    c_df.country = country  # remember which country we work on, just in case\n",
    "    \n",
    "    c_df['days-td'] = c_df.index - c_df.index.min()  # days as TimeDelta type\n",
    "    c_df['days'] = c_df['days-td'].astype(\"timedelta64[D]\").astype(float)\n",
    "    \n",
    "    c_df['new_confirmed'] = c_df['confirmed'].diff()\n",
    "    c_df['new_deaths'] = c_df['deaths'].diff()\n",
    "    \n",
    "    c_df['confirmed_pct'] = c_df['confirmed'].pct_change()+1\n",
    "    c_df['deaths_pct'] = c_df['deaths'].pct_change()+1\n",
    "    \n",
    "    #return c_df\n",
    "    # growth rate\n",
    "    c_df['deaths_double_time'] = double_time_exponential(c_df['deaths_pct'].values)\n",
    "    c_df['confirmed_double_time'] = double_time_exponential(c_df['confirmed_pct'].values)\n",
    "    c_df['deaths_growth_rate'] = growth_rate(c_df['deaths_double_time'].values)\n",
    "    c_df['confirmed_growth_rate'] = growth_rate(c_df['confirmed_double_time'].values)\n",
    "\n",
    "    return c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = stack_country(\"Germany\")\n",
    "#c.tail(n=5)\n",
    "c2 = stack_country(\"United Kingdom\")\n",
    "#c.tail(n=5)\n",
    "#c2 = stack_country(\"Spain\")\n",
    "#c.tail(n=5)\n",
    "#c2 = stack_country(\"Italy\")\n",
    "#c2.tail(n=5)\n",
    "#c2 = stack_country(\"France\")\n",
    "#c2.tail(n=5)\n",
    "#c2 = stack_country(\"China\")\n",
    "#c2 = stack_country(\"US\")\n",
    "\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overview_plot(c_df):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(8, 14))\n",
    "    ax = axes[0]\n",
    "    set_date_formatting(ax)\n",
    "    ax.plot(c_df.index, c_df['confirmed'], 'o-b', label='confirmed')\n",
    "    ax.plot(c_df.index, c_df['deaths'], 'o-r', label='deaths')\n",
    "    ax.legend(loc='center left')\n",
    "    country = c_df.country\n",
    "    ax.set_title(country + \" accumulated data\")\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    set_date_formatting(ax)\n",
    "    ax.plot(c_df.index, c_df['deaths_double_time'], 'xr', label='double time deaths')\n",
    "    ax.plot(c_df.index, c_df['confirmed_double_time'], 'ob', label='double time confirmed')\n",
    "    ax.legend(loc='center left')\n",
    "    ax.set_ylabel('days to double numbers \\n bigger is better')\n",
    "    maxy = min(10, max(c_df['confirmed_double_time']))\n",
    "    ax.set_ylim(0, maxy)\n",
    "\n",
    "    ax = axes[2]\n",
    "    set_date_formatting(ax)\n",
    "    ax.plot(c_df.index, c_df['deaths_growth_rate'], 'xr', label='growth rate deaths')\n",
    "    ax.plot(c_df.index, c_df['confirmed_growth_rate'], 'ob', label='confirmed growth rate')\n",
    "    ax.legend(loc='center left')\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.set_ylabel('growth rate r in\\n f(t) = exp(r*t)\\n(smaller is better)')\n",
    "    \n",
    "    # fig.savefig(f\"figures/{country}-overview.svg\")\n",
    "    return axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_plot(c);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_plot(c2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute doubling time (and growth rate) for a longer sequence of days (by fitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_params(**par):\n",
    "    end='\\n'\n",
    "    s = \"\"\n",
    "    for p in par:\n",
    "        s += f\"{p:3} : {par[p]:.3g}\" + end\n",
    "    return s\n",
    "\n",
    "\n",
    "def model(xdata, r, t0, a0):\n",
    "    return np.exp(r*(xdata-t0))+a0\n",
    "\n",
    "\n",
    "\n",
    "def exp_fit(xdata, ydata, p0):\n",
    "    r, t0, a0 = p0\n",
    "    \n",
    "    def least_squares(r, t0, a0):\n",
    "        yvar = 10\n",
    "        return sum((ydata - model(xdata, r, t0, a0))**2)/yvar\n",
    "    \n",
    "    m = iminuit.Minuit(least_squares, \n",
    "                       r=r, t0=t0, a0=a0, error_r=0.02, error_t0=0.2, error_a0=1, \n",
    "                       errordef=1)\n",
    "    res = m.migrad()\n",
    "    print(f\"reduced chi^2: {m.fval / (len(ydata) - 3)}\")\n",
    "    r, t0, a0 = m.np_values()\n",
    "    print(pretty_params(r=r, t0=t0, a0=a0))\n",
    "    \n",
    "    return m, res\n",
    "\n",
    "def plot(xdata, ydata, r, t0, a0, annotate=\"\"):\n",
    "    #r, t0, a0 = m.np_values()\n",
    "\n",
    "    fitted = model(xdata, r, t0, a0)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot(xdata, ydata, 'og')\n",
    "    ax.plot(xdata, fitted, '-b')\n",
    "    ax.legend([\"data\", f\"fit: $r={r}, t0={t0}, a0={a0}\"])\n",
    "    #ax.set_title(f\"Infections $n(t)$ ({pretty_params(param_infections, end=', ')})\")\n",
    "    ax.set_title(annotate)\n",
    "    #ax.xaxis.set_major_locator(matplotlib.dates.DayLocator())\n",
    "    #ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b %d'))\n",
    "    #ax.tick_params(axis='x', rotation=90)\n",
    "    #fig.savefig('figures/infections-with-model-fit.svg')\n",
    "    # print(fitted_infections)\n",
    "    return ax\n",
    "\n",
    "def test_model(): \n",
    "    xdata = np.linspace(0, 30, 4)\n",
    "    ydata = 0 + np.exp(0.1*(xdata - 0)) + 5*np.random.random_sample(xdata.shape)    \n",
    "    m, res = exp_fit(xdata, ydata, (.1, 0.00, 0.0))\n",
    "    r, t0, a0 = m.np_values()\n",
    "    plot(xdata, ydata, r, t0, a0)\n",
    "    return res, m, xdata, ydata\n",
    "\n",
    "\n",
    "res, m, xdata, ydata = test_model()\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential fit through last n days\n",
    "\n",
    "xdata_0 = (series.index[start:end] - series.index[0])\n",
    "xdata = np.array((xdata_0.astype(\"timedelta64[D]\").astype(float)))\n",
    "ydata = series.values[start:end]\n",
    "# Attempt fit\n",
    "m, res = exp_fit(xdata, ydata, (.1, 0.00, 0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_rate_n_days(series, n=5):\n",
    "    \"\"\"Use the last 4 data points to estimate growth rate (and doubling time) for each day\"\"\"\n",
    "    par = pd.DataFrame(index=series.index, columns=['r', 't0', 'a0', 'chi2'])\n",
    "    print(f\"Data stack shape = {series.shape}\")\n",
    "    for i in range(n, len(series)):\n",
    "        start = i-n\n",
    "        end = i\n",
    "        print(f\"Working on {start} to {end}, this is {start}/{len(series-n)}\")\n",
    "        xdata_0 = (series.index[start:end] - series.index[0])\n",
    "        xdata = np.array((xdata_0.astype(\"timedelta64[D]\").astype(float)))\n",
    "        ydata = series.values[start:end]\n",
    "        # Attempt fit\n",
    "        m, res = exp_fit(xdata, ydata, (.1, 0.00, 0.0))\n",
    "        r, t0, a0 = m.np_values()\n",
    "        par.iloc[i].at['r'] = r\n",
    "        par.iloc[i].at['t0'] = t0\n",
    "        par.iloc[i].at['a0'] = a0\n",
    "        print(f\"r={r:10}, t0={t0:10}, a0={a0:10}\")\n",
    "        plot(xdata, ydata, r, t0, a0)\n",
    "            \n",
    "    return par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "c = stack_country('Germany')\n",
    "p = grow_rate_n_days(c['confirmed'][-20:])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.tail(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.at['r', 3] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log basics ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log \n",
    "log(2)/log(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://en.wikipedia.org/wiki/Doubling_time\n",
    "    \n",
    "$$\\Delta t = (t_2 - t_1) * \\left(\\frac{\\log(2)}{\\log\n",
    "    \\left(\\frac{f(t_2)}{f(t_1)}\\right)}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "def double_time_exponential(t1, t2, q1, q2):\n",
    "    return (t2 - t1) * (log(2) / log(q2/q1) )\n",
    "\n",
    "def growth_rate(double_time):\n",
    "    return log(2)/double_time\n",
    "\n",
    "\n",
    "t1, t2, q1, q2 = 0, 1, 1, 2\n",
    "double_time_exponential(t1, t2, q1, q2), growth_rate(double_time_exponential(t1, t2, q1, q2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**(1/double_time_exponential(0, 1, 1, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/math.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(0.5)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.exp(0.6931471805599453*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
