{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R factor - basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [basic reproduction number (Wikipedia)](https://en.wikipedia.org/wiki/Basic_reproduction_number) can be thought of as the expected number of cases directly generated by one case in a population where all individuals are susceptible to infection. \n",
    "\n",
    "One way to represent $R$ is $R = \\beta \\,\\tau $ where $\\beta$ represents an average infection-producing contacts per unit time and $\\tau$ the infectious period.\n",
    "\n",
    "For exponential growth with case numbers N(t) increasing as $N(t) = N(t_0) R^{t/\\tau}$, the _logarithmic growth rate K_ can be used to describe the growth: $K = \\frac{d ln(N)}{dt}$.\n",
    "\n",
    "The relationship between $R$ and $K$ is $R = \\exp(K\\tau)$ or equivalently $K = \\ln(R)/\\tau$.\n",
    "\n",
    "[1] [Basic reproduction number (Wikipedia)](https://en.wikipedia.org/wiki/Basic_reproduction_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical exploration of the very basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 15\n",
    "t = np.arange(0, n_points, 1)\n",
    "# tdiff = np.arange(0.5, n_points - 1, 1)\n",
    "N0 = 1              # infections on day 0\n",
    "tau = 4             # average infectious time\n",
    "R0 = 2.1            # R0 - number of infections per period tau\n",
    "n = N0*(R0**(t/tau))   # compute vector n with perfect exponential growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, n, 'o', label=f'n = {N0} * ({R0} ^ (t/{tau}))')\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"time [days]\");\n",
    "ax.set_ylabel(\"n(t)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute K and R0 from this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_n = np.log(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "K = np.diff(ln_n)\n",
    "ax.plot(t, ln_n, 'o-', label='ln(n)')\n",
    "ax.plot(tdiff, K, 'x-', label='K = d ln(n) / dt')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R0_reconstructed = np.exp(K*tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R0_reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert R0_reconstructed[0] == R0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute R0 from measured data\n",
    "\n",
    "### Method 1: \n",
    "\n",
    "The bulletin from the Robert Koch institute [2] reports that an average infectious period of $\\tau = 4$ days is assumed. Based on that information, the description of the method to compute $R$ (or $R_0$) is [3]\n",
    "\n",
    "- compute an average $<n>_1$ of daily new infections over 4 days (say days 0 to 3)\n",
    "- compute an average $<n>_2$ of daily new infections over 4 subsequent days (say days 4 to 7)\n",
    "- compute the quotient $<n>_2 / <n>_1$ \n",
    "\n",
    "The method is references as being reported in [4].\n",
    "\n",
    "[2] [Robert Koch Institute: Epidemiologisches Bulletin 17 | 2020 23. April 2020, page 13 onwards](https://www.rki.de/DE/Content/Infekt/EpidBull/Archiv/2020/Ausgaben/17_20.html)\n",
    "\n",
    "[3] \"_Bei einer konstanten Generationszeit von 4 Tagen, ergibt sich R als Quotient der Anzahl von Neuerkran- kungen in zwei aufeinander folgenden Zeitabschnitten von jeweils 4 Tagen. Der so ermittelte R-Wert wird dem letzten dieser 8 Tage zugeordnet, weil erst dann die gesamte Information vorhanden ist._\"\n",
    "\n",
    "[4] Wallinga J, Lipsitch M: How generation intervals shape the relationship between growth rates and reproductive numbers. [Proceedings of the Royal Society B:\n",
    "Biological Sciences 2007;274(1609):599â€“60](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1766383/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(n, index=t)    # turn numpy array into pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = s.diff().dropna()        # compute the change from day to day \n",
    "                             # (i.e. dn/dt, time unit is one day\n",
    "                             # and drop the first value for which can't compute dn/dt\n",
    "                             # and for which the `diff` method has insert NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = c[0:4].mean()        # take mean over first 4 days\n",
    "mean2 = c[4:8].mean()        # take mean over next 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotient = mean2 / mean1     # Compute R as quotient of the two means\n",
    "quotient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert quotient == R0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be okay (for perfect exponential growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### method 2: K from d log(n)/dt and tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.log(s).diff().dropna()\n",
    "\n",
    "R0_reconstructed2 = np.exp(K*tau)\n",
    "R0_reconstructed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert R0_reconstructed2.values[0] == R0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complicated example with time-dependent R0\n",
    "\n",
    "Now we'll use the same equations on synthetic data, to see if we can re-construct the underlying R0.\n",
    "\n",
    "### Step changes in R0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 50\n",
    "t = np.arange(0, n_points, 1)\n",
    "N0 = 3\n",
    "tau = 4\n",
    "# R0_td = 3 - 0.1*(np.sin(t/n_points*2*np.pi*2))   \n",
    "R0_td = np.zeros(shape=t.shape)\n",
    "R0_td[:n_points//3] = 3\n",
    "R0_td[n_points//3:2*n_points//3] = 2\n",
    "R0_td[2*n_points//3:] = 2.5\n",
    "\n",
    "# R0_td = 2.0 - 0.5*(t/n_points)\n",
    "R0 = 2.0\n",
    "# n_td = N0*(R0_td**(t/tau))   # inaccurate, need fake_growth for this\n",
    "n = N0*(R0**(t/tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_growth(t, R, tau: float, N0=1):\n",
    "    \"\"\"expect \n",
    "    - t: a vector (counting days)\n",
    "    - Rs: a vector with the desired R for each day\n",
    "    - tau: a constant for the assumption of the average infectious period\n",
    "    \n",
    "    Assumes exponential growth according to\n",
    "    N[i] = N0*(R**(t/tau)) from day i to day i+1 with rate R[i].\n",
    "    \n",
    "    and compute the increase from day i to day i by computing\n",
    "    dN[i] = N[i+1] - N[i]\n",
    "    \n",
    "    Compute a time series n, so that this accumulates dN. Return n.\n",
    "    \"\"\"\n",
    "    def f(R_, t_, tau, N0):\n",
    "        return N0 * R_**(t_/tau)\n",
    "    \n",
    "    dN = np.zeros(shape=t.shape)\n",
    "    n = np.zeros(shape=t.shape)\n",
    "    assert len(t) == len(R)\n",
    "    assert t[0] == 0\n",
    "    dN[0] = N0\n",
    "    for i in range(1, len(t)):\n",
    "        # if R < 1, might get negative dN. Let's not allow this for now.\n",
    "        assert R[i] >= 1, f\"R[{i}] = {R[i]} <= 1.0\"\n",
    "        N_i = f(R[i], t[i], tau, N0)\n",
    "        N_im1 = f(R[i], t[i-1], tau, N0)   # read N_i_minus_1\n",
    "        dN_i = N_i - N_im1\n",
    "        # import IPython\n",
    "        # IPython.embed()\n",
    "        dN[i] = dN_i\n",
    "        if dN_i < 0:\n",
    "            print(f\"dN[{i}] = {dN[i]}, N[{i}] = {N_i}, N[{i-1}] = {N_im1}, R[{i}] = {R[i]}\")\n",
    "            # IPython.embed()\n",
    "    \n",
    "    # Compute accumulated cases\n",
    "    # for day 0, we expect N0 (assuming that t[0] == 0)\n",
    "    assert t[0] == 0\n",
    "    n[0] = N0\n",
    "    for i in range(1, len(t)):\n",
    "        n[i] = n[i-1] + dN[i]\n",
    "    return n\n",
    "\n",
    "def test_fake_growth():\n",
    "    \"\"\" Assumer constant growth rate, and expect exponential growth.\"\"\"\n",
    "    npoints = 20\n",
    "    t = np.arange(0, npoints, 1)\n",
    "    R_number = 2.1\n",
    "    R = np.ones(shape=t.shape) * R_number\n",
    "    tau = 3.5\n",
    "    N0 = 4\n",
    "    n1 = fake_growth(t, R, tau, N0)\n",
    "    n2 = N0 * R_number ** (t / tau)\n",
    "    diff = n2-n1\n",
    "    max_err = np.max(np.abs(diff))\n",
    "    print(f\"Max error is {max_err}\")\n",
    "    assert max_err < 1e-15\n",
    "    return n1, n2\n",
    "\n",
    "test_fake_growth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fake = fake_growth(t, R0_td, tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fake = pd.Series(n_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax, ax2, ax3) = plt.subplots(3, 1)\n",
    "# ax.plot(t, n, 'o', label=f'n = {N0} * ({R0} ^ (t/{tau}))')\n",
    "# ax.plot(t, n_td, 'o', color='C1', label=f'n = {N0} * (R0(t) ^ (t/{tau}))')\n",
    "ax.step(t, n_fake, 'o-', color='C3', label=f'n = fake growth)')\n",
    "\n",
    "ax3.plot(t, R0_td, '-o',color='C1', label=\"time dependent R0\")\n",
    "\n",
    "ax2.bar(t, n_fake.diff(), label='daily new cases')\n",
    "\n",
    "ax3.set_xlabel('time [days]');\n",
    "ax.legend(), \n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'R_td' : R0_td, 'n_td' : n_fake, 'c_td' : n_fake.diff()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: RKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing makes things a lot better:\n",
    "df['smooth_c'] = df['c_td'].rolling(7, center=True, \n",
    "                                    win_type='gaussian', min_periods=7).mean(std=3)\n",
    "# but important to have min_periods the same as the rolling period\n",
    "\n",
    "#df['mean4d'] = df['c_td'].rolling(4).mean()\n",
    "df['mean4d'] = df['smooth_c'].rolling(4).mean()\n",
    "\n",
    "df['R_td-recon'] = df['mean4d'] / df['mean4d'].shift(4)\n",
    "\n",
    "df[['R_td', 'R_td-recon', 'n_td', 'mean4d']].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['R_td', 'R_td-recon', 'n_td', 'mean4d']].tail(n=4)\n",
    "df[['R_td', 'R_td-recon']].tail(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, df['R_td'], '-x', label='R_td')\n",
    "ax.plot(t, df['R_td-recon'], 'o', label=f'n = R_td-recon')\n",
    "ax.legend()\n",
    "ax.set_title('Method 1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['K'] = np.log(df['n_td']).diff(periods=1)\n",
    "\n",
    "df['R_td-recon2'] = np.exp(df['K'] * tau)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['R_td', 'R_td-recon2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['R_td', 'R_td-recon2']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, df['R_td'], '-x', label='R_td')\n",
    "ax.plot(t, df['R_td-recon2'], 'o', color='C2', label=f'R_td-recon2')\n",
    "ax.legend()\n",
    "ax.set_title('Method 2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(t, df['R_td'], '-x', linewidth=3, label='R_td')\n",
    "ax.plot(t, df['R_td-recon'], 'o:', color=\"C1\", label=f'n = R_td-recon')\n",
    "ax.plot(t, df['R_td-recon2'], 'o:', color=\"C2\", label=f'n = R_td-recon2')\n",
    "ax.legend()\n",
    "ax.set_title('Method 1 and 2 in comparison');\n",
    "ax.grid('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: random noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 50\n",
    "t = np.arange(0, n_points, 1)\n",
    "N0 = 3\n",
    "tau = 4\n",
    "R0_td = np.zeros(shape=t.shape) + 2   \n",
    "noise = np.random.uniform(size=t.shape) - 0.5\n",
    "# add 10% noise (relative error to actual signal)\n",
    "n_fake = pd.Series(fake_growth(t, R0_td, tau) * (1 + 0.1 * noise))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax, ax2, ax3) = plt.subplots(3, 1)\n",
    "ax.step(t, n_fake, 'o-', color='C3', label=f'n = fake growth)')\n",
    "ax3.plot(t, R0_td, '-o',color='C1', label=\"time dependent R0\")\n",
    "ax2.bar(t, n_fake.diff(), label='daily new cases')\n",
    "\n",
    "ax3.set_xlabel('time [days]');\n",
    "ax.legend(), \n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'R_td' : R0_td, 'n_td' : n_fake, 'c_td' : n_fake.diff()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: RKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean4d'] = df['c_td'].rolling(4).mean()\n",
    "df['R_td-recon'] = df['mean4d'] / df['mean4d'].shift(4)\n",
    "\n",
    "df[['R_td', 'R_td-recon', 'n_td', 'mean4d']].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, df['R_td'], '-x', label='R_td')\n",
    "ax.plot(t, df['R_td-recon'], 'o', label=f'n = R_td-recon')\n",
    "ax.legend()\n",
    "ax.set_title('Method 1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The noise seems amplified in the reconstructed R.\n",
    "\n",
    "Let's try some smoothing of the noisy data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['smooth_c'] = df['c_td'].rolling(7, center=True, \n",
    "                                    win_type='gaussian', min_periods=7).mean(std=3)\n",
    "df['mean4d'] = df['smooth_c'].rolling(4).mean()\n",
    "\n",
    "\n",
    "df['R_td-recon'] = df['mean4d'] / df['mean4d'].shift(4)\n",
    "\n",
    "df[['R_td', 'R_td-recon', 'n_td', 'mean4d']].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(t, df['R_td'], '-x', label='R_td')\n",
    "ax.plot(t, df['R_td-recon'], 'o', label=f'n = R_td-recon')\n",
    "ax.legend()\n",
    "ax.set_title('Method 1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "1. Use RKI algorithm: seems stable, returns the correct value R (after ~tau days) if R is constant\n",
    "\n",
    "2. Use smoothing for the case numbers (or the diff of the case numbers) to improve estimates.\n",
    "\n",
    "3. It is important for the rolling averages (both for the smoothing of the diff, and for the\n",
    "4-day average) to use all data points, and not to ignore some. If we use 'min_values=' to allow fewer data points, the reconstructed R values show systematic errors at the beginning and end of the interval. \n",
    "\n",
    "(Maybe that can be improved.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draft algorithm here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_R(daily_change, tau=4):\n",
    "    \"\"\"Given a time series s, estimate R based on description from RKI [1].\n",
    "    \n",
    "    [1] [Robert Koch Institute: Epidemiologisches Bulletin 17 | 2020 23. April 2020]\n",
    "    https://www.rki.de/DE/Content/Infekt/EpidBull/Archiv/2020/Ausgaben/17_20.html\n",
    "\n",
    "    Steps: \n",
    "    \n",
    "    1. Compute change from day to day\n",
    "    2. Take tau-day averages (tau=4 is recommended as of April/May 2020)\n",
    "    3. divide average from days 4 to 7 by averages from day 0 to 3, and use this data point for day[7]\n",
    "\n",
    "    \"\"\"\n",
    "    # change = s.diff()\n",
    "    change = daily_change\n",
    "    mean4d = change.rolling(tau).mean()\n",
    "    R = mean4d / mean4d.shift(tau)\n",
    "    R2 = R.shift(-tau)  # this is not the RKI method, but seems more appropriate.\n",
    "    return R2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(t, df['R_td'], '-x', linewidth=3, label='R_td')\n",
    "\n",
    "ax.plot(t, compute_R(df['n_td'].diff()), 'o:', color=\"C1\", label=f'n = R_td-recon')\n",
    "ax.legend()\n",
    "ax.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ax.plot(t, df['R_td'], '-x', linewidth=3, label='R_td')\n",
    "ax.plot(t, compute_R(df['n_td'].diff()), 'o:', color=\"C1\", label=f'n = R_td-recon')\n",
    "ax.legend()\n",
    "ax.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oscovida\n",
    "from oscovida import compute_growth_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases, deaths = oscovida.get_country_data(\"Germany\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def min_max_in_past_n_days(series, n, at_least = [0.75, 1.25], alert=[0.5, 100]):\n",
    "    \"\"\"Given a time series, find the min and max values in the time series within the last n days.\n",
    "    \n",
    "    If those values are within the interval `at_least`, then use the values in at_least as the limits.\n",
    "    if those values are outside the interval `at_least` then exchange the interval accordingly.\n",
    "    \n",
    "    If the values exceed the min and max value in 'alerts', then print an error message.\n",
    "    Return min, max.\n",
    "    \"\"\"\n",
    "    if n > len(series):\n",
    "        n = len(series)\n",
    "        \n",
    "    series = series.replace(math.inf, math.nan)\n",
    "        \n",
    "    min_ = series[-n:].min()\n",
    "    max_ = series[-n:].max()\n",
    "    \n",
    "    if min_ < at_least[0]:\n",
    "        min_final = min_\n",
    "    else:\n",
    "        min_final = at_least[0]\n",
    "        \n",
    "    if max_ > at_least[1]:\n",
    "        max_final = max_\n",
    "    else:\n",
    "        max_final = at_least[1]\n",
    "        \n",
    "    if max_final > alert[1]:\n",
    "        print(f\"Large value for R_max = {max_final} > {alert[1]} in last {n} days: \\n\", series[-n:])\n",
    "    if min_final < alert[0]:\n",
    "        print(f\"Small value for R_min = {min_final} < {alert[0]} in last {n} days: \\n\", series[-n:])\n",
    "        \n",
    "    print(f\"DDD: min_={min_}, max_={max_}\")\n",
    "    return min_final, max_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cases, deaths = oscovida.get_country_data(\"Iran\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1 , figsize=(12, 4))\n",
    "# change, smooth, smooth2 = oscovida.compute_daily_change(cases)\n",
    "oscovida.plot_growth_factor(ax, cases, \"C1\")\n",
    "# oscovida.plot_growth_factor(ax, deaths, \"C0\")\n",
    "diff = cases.diff()\n",
    "smooth_diff = diff.rolling(9, center=True, win_type='gaussian').mean(std=4)\n",
    "\n",
    "R = compute_R(smooth_diff)\n",
    "ax.plot(R.index, R, \"-C4\", label=r\"R (estimated with $\\tau$=4 days using RKI algorithm)\", linewidth=3)\n",
    "\n",
    "ax.legend()\n",
    "min_, max_ = min_max_in_past_n_days(R, 28);\n",
    "ax.plot([R.index.min(), R.index.max()], [min_, min_], 'b-')\n",
    "ax.plot([R.index.min(), R.index.max()], [max_, max_], 'b-')\n",
    "ax.set_ylim([min_, max_]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R[-21:].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.plot(R.index, R, \"C2\", label=\"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oscovida.overview(\"Iran\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reproducion_number(ax, series, color):\n",
    "    \"\"\"Documentation to be added\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    # data for computation or R\n",
    "    # change, smooth, smooth2 = oscovida.compute_daily_change(series)\n",
    "    \n",
    "    smooth = series.diff().rolling(7, center=True, win_type='gaussian').mean(std=4)\n",
    "    \n",
    "    R = compute_R(smooth)\n",
    "    ax.plot(R.index, R, \"-C4\", label=r\"estimated R (assume $\\tau$=4 days, using RKI algorithm)\", linewidth=3)\n",
    "\n",
    "    # choose y limits so that all data points of R in the last 28 days are visible\n",
    "    min_, max_ = min_max_in_past_n_days(R, 28);\n",
    "    ax.set_ylim([min_, max_]);\n",
    "\n",
    "    # Plot ylim interval for debugging\n",
    "    # ax.plot([R.index.min(), R.index.max()], [min_, min_], 'b-')\n",
    "    # ax.plot([R.index.min(), R.index.max()], [max_, max_], 'b-')\n",
    "    \n",
    "     # get smooth data for growth factor from plot 1 to base this plot on\n",
    "    (f, f_label) , (f_smoothed, smoothed_label) = compute_growth_factor(series)\n",
    "    \n",
    "    label = series.country + \" \" + series.label + \" daily growth factor \" + f_label\n",
    "    ax.plot(f.index, f.values, 'o', color=color, alpha=0.3, label=label)\n",
    "\n",
    "    label = series.country + \" \" + series.label + \" daily growth factor \" + smoothed_label\n",
    "    ax.plot(f_smoothed.index, f_smoothed.values, '-', color=color, label=label, linewidth=LW)\n",
    "\n",
    "    ax.set_ylabel(\"R and daily growth factor\")\n",
    "    # plot line at 0\n",
    "    ax.plot([series.index.min(), series.index.max()], [1.0, 1.0], '-k') # label=\"critical value\"\n",
    "    ax.legend()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1 , figsize=(12, 4))\n",
    "LW = oscovida.LW\n",
    "plot_reproducion_number(ax, cases, 'C1')\n",
    "LW = oscovida.LW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
